{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdk455/NUS-Lab/blob/main/SWS3009Lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1qhsM4Kbtp7"
      },
      "source": [
        "# SWS3009 Lab 3 Introduction to Deep Learning\n",
        "\n",
        "\n",
        "|      Members            |\n",
        "---------------------|\n",
        " |    CAI Jiajun              |\n",
        " |       MA Jiaolin            |\n",
        "|   XIE Jinxiang             |\n",
        "\n",
        "This lab should be done by both Deep Learning members of the team. Please ensure that you fill in the names of <b>both</b> team members in the spaces above. Answer <b>all</b> your questions on <b>this Python Notebook.</b>\n",
        "\n",
        "## Submission Instructions\n",
        "\n",
        "Please submit this Python notebook to Canvas on the deadline provided.\n",
        "\n",
        "Marks will be awarded as follows:\n",
        "\n",
        "**0 marks**: No/empty/Non-English submission\n",
        "\n",
        "**1 mark** : Poor submission\n",
        "\n",
        "**2 marks**: Acceptable submission\n",
        "\n",
        "**3 marks**: Good submission\n",
        "\n",
        "\n",
        "## 1. Introduction\n",
        "\n",
        "We will achieve the following objectives in this lab:\n",
        "\n",
        "    1. An understanding of the practical limitations of using dense networks in complex tasks\n",
        "    2. Hands-on experience in building a deep learning neural network to solve a relatively complex task.\n",
        "    \n",
        "\n",
        "Each step may take a long time to run. You and your partner may want to work out how to do things simultaneously, but please do not miss out on any learning opportunities.\n",
        "\n",
        "\n",
        "## 2. Submission Instructions\n",
        "\n",
        "Please submit your answer book to Canvas by the deadline.\n",
        "\n",
        "## 3. Creating a Dense Network for CIFAR-10\n",
        "\n",
        "We will now begin building a neural network for the CIFAR-10 dataset. The CIFAR-10 dataset consists of 50,000 32x32x3 (32x32 pixels, RGB channels) training images and 10,000 testing images (also 32x32x3), divided into the following 10 categories:\n",
        "\n",
        "    1. Airplane\n",
        "    2. Automobile\n",
        "    3. Bird\n",
        "    4. Cat\n",
        "    5. Deer\n",
        "    6. Dog\n",
        "    7. Frog\n",
        "    8. Horse\n",
        "    9. Ship\n",
        "    10. Truck\n",
        "    \n",
        "In the first two parts of this lab we will create a classifier for the CIFAR-10 dataset.\n",
        "\n",
        "### 3.1 Loading the Dataset\n",
        "\n",
        "We begin firstly by creating a Dense neural network for CIFAR-10. The code below shows how we load the CIFAR-10 dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z01HdIb1btp8",
        "outputId": "912fe6b4-b448-427b-a4d5-66c11bfba71b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "def load_cifar10():\n",
        "    (train_x, train_y), (test_x, test_y) = cifar10.load_data()\n",
        "    train_x = train_x.reshape(train_x.shape[0], 3072) # Question 1\n",
        "    test_x = test_x.reshape(test_x.shape[0], 3072) # Question 1\n",
        "    train_x = train_x.astype('float32')\n",
        "    test_x = test_x.astype('float32')\n",
        "    train_x /= 255.0\n",
        "    test_x /= 255.0\n",
        "    ret_train_y = to_categorical(train_y,10)\n",
        "    ret_test_y = to_categorical(test_y, 10)\n",
        "\n",
        "    return (train_x, ret_train_y), (test_x, ret_test_y)\n",
        "\n",
        "\n",
        "(train_x, train_y), (test_x, test_y) = load_cifar10()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px-7eNvtbtp8"
      },
      "source": [
        "----\n",
        "\n",
        "#### Question 1\n",
        "\n",
        "Explain what the following two  statements do, and where the number \"3072\" came from:\n",
        "\n",
        "```\n",
        "  train_x = train_x.reshape(train_x.shape[0], 3072) # Question 1\n",
        "  test_x = test_x.reshape(test_x.shape[0], 3072) # Question 1\n",
        "```\n",
        "\n",
        "**Please put your answers in the attached answer books**\n",
        "\n",
        "Answer:\n",
        "\n",
        "The two statements reshape the input data arrays train_x and test_x to have a specific shape, where each row represents a sample and each column represents a feature.\n",
        "\n",
        "In this context, the number \"3072\" corresponds to the total number of features (or dimensions) in the input data. It is calculated based on the assumption that the input data is a three-dimensional array, representing images in the CIFAR-10 dataset, where each image has a shape of 32x32 pixels and three color channels (RGB).\n",
        "\n",
        "The calculation of 3072 is derived as follows: 32 (height) x 32 (width) x 3 (RGB channels) = 3072.\n",
        "\n",
        "The purpose of reshaping the data is often to transform the data into a format suitable for the subsequent steps of model training or evaluation. In this case, the reshaping ensures that each sample in the input data has a flat representation with 3072 features, allowing it to be compatible with the input requirements of the MLP classifier or any other model being used.\n",
        "\n",
        "By reshaping the data in this way, each row in train_x and test_x represents an image sample with 3072 feature values. This reshaping is necessary because many machine learning algorithms, including MLPs, require the input data to be in a specific shape or format before training or making predictions.\n",
        "\n",
        "\n",
        "### 3.2 Building the MLP Classifier\n",
        "\n",
        "In the code box below, create a new fully connected (dense) multilayer perceptron classifier for the CIFAR-10 dataset. To begin with, create a network with one hidden layer of 1024 neurons, using the SGD optimizer. You should output the training and validation accuracy at every epoch, and train for 50 epochs:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxAMw3Jkbtp9",
        "outputId": "42e65c66-4aa6-475a-bbbc-98b907fd9e3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "391/391 [==============================] - 7s 6ms/step - loss: 1.9512 - accuracy: 0.3099 - val_loss: 1.8291 - val_accuracy: 0.3574\n",
            "Epoch 2/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7982 - accuracy: 0.3730 - val_loss: 1.7716 - val_accuracy: 0.3840\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.7366 - accuracy: 0.3976 - val_loss: 1.7407 - val_accuracy: 0.3816\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.6935 - accuracy: 0.4130 - val_loss: 1.6819 - val_accuracy: 0.4146\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.6567 - accuracy: 0.4266 - val_loss: 1.6484 - val_accuracy: 0.4252\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.6278 - accuracy: 0.4359 - val_loss: 1.6350 - val_accuracy: 0.4267\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.6020 - accuracy: 0.4455 - val_loss: 1.6260 - val_accuracy: 0.4287\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.5813 - accuracy: 0.4534 - val_loss: 1.5919 - val_accuracy: 0.4444\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.5605 - accuracy: 0.4613 - val_loss: 1.5726 - val_accuracy: 0.4465\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.5431 - accuracy: 0.4645 - val_loss: 1.5546 - val_accuracy: 0.4577\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.5270 - accuracy: 0.4701 - val_loss: 1.5483 - val_accuracy: 0.4613\n",
            "Epoch 12/50\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.5101 - accuracy: 0.4772 - val_loss: 1.5332 - val_accuracy: 0.4612\n",
            "Epoch 13/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.4959 - accuracy: 0.4833 - val_loss: 1.5489 - val_accuracy: 0.4533\n",
            "Epoch 14/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.4834 - accuracy: 0.4879 - val_loss: 1.5109 - val_accuracy: 0.4667\n",
            "Epoch 15/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.4699 - accuracy: 0.4919 - val_loss: 1.4979 - val_accuracy: 0.4727\n",
            "Epoch 16/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.4571 - accuracy: 0.4965 - val_loss: 1.4955 - val_accuracy: 0.4795\n",
            "Epoch 17/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.4450 - accuracy: 0.4987 - val_loss: 1.4868 - val_accuracy: 0.4752\n",
            "Epoch 18/50\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.4329 - accuracy: 0.5052 - val_loss: 1.4810 - val_accuracy: 0.4770\n",
            "Epoch 19/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.4210 - accuracy: 0.5106 - val_loss: 1.4753 - val_accuracy: 0.4789\n",
            "Epoch 20/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.4106 - accuracy: 0.5124 - val_loss: 1.4752 - val_accuracy: 0.4792\n",
            "Epoch 21/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.4014 - accuracy: 0.5157 - val_loss: 1.4638 - val_accuracy: 0.4890\n",
            "Epoch 22/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.3911 - accuracy: 0.5203 - val_loss: 1.4622 - val_accuracy: 0.4816\n",
            "Epoch 23/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.3807 - accuracy: 0.5236 - val_loss: 1.4525 - val_accuracy: 0.4895\n",
            "Epoch 24/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.3681 - accuracy: 0.5304 - val_loss: 1.4243 - val_accuracy: 0.4990\n",
            "Epoch 25/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.3595 - accuracy: 0.5305 - val_loss: 1.4219 - val_accuracy: 0.5007\n",
            "Epoch 26/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.3511 - accuracy: 0.5328 - val_loss: 1.4425 - val_accuracy: 0.4913\n",
            "Epoch 27/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.3432 - accuracy: 0.5362 - val_loss: 1.4428 - val_accuracy: 0.4958\n",
            "Epoch 28/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.3351 - accuracy: 0.5401 - val_loss: 1.4357 - val_accuracy: 0.4868\n",
            "Epoch 29/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.3244 - accuracy: 0.5416 - val_loss: 1.4325 - val_accuracy: 0.4869\n",
            "Epoch 30/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.3169 - accuracy: 0.5459 - val_loss: 1.4112 - val_accuracy: 0.4998\n",
            "Epoch 31/50\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.3095 - accuracy: 0.5489 - val_loss: 1.4079 - val_accuracy: 0.5033\n",
            "Epoch 32/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.3018 - accuracy: 0.5513 - val_loss: 1.3978 - val_accuracy: 0.5078\n",
            "Epoch 33/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.2928 - accuracy: 0.5551 - val_loss: 1.3921 - val_accuracy: 0.5028\n",
            "Epoch 34/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.2873 - accuracy: 0.5565 - val_loss: 1.3866 - val_accuracy: 0.5149\n",
            "Epoch 35/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.2799 - accuracy: 0.5580 - val_loss: 1.3868 - val_accuracy: 0.5103\n",
            "Epoch 36/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.2724 - accuracy: 0.5610 - val_loss: 1.3823 - val_accuracy: 0.5134\n",
            "Epoch 37/50\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.2633 - accuracy: 0.5669 - val_loss: 1.3650 - val_accuracy: 0.5219\n",
            "Epoch 38/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.2566 - accuracy: 0.5678 - val_loss: 1.3893 - val_accuracy: 0.5067\n",
            "Epoch 39/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.2490 - accuracy: 0.5700 - val_loss: 1.3817 - val_accuracy: 0.5134\n",
            "Epoch 40/50\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 1.2421 - accuracy: 0.5741 - val_loss: 1.3836 - val_accuracy: 0.5073\n",
            "Epoch 41/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.2332 - accuracy: 0.5763 - val_loss: 1.4340 - val_accuracy: 0.4925\n",
            "Epoch 42/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.2283 - accuracy: 0.5781 - val_loss: 1.3874 - val_accuracy: 0.5110\n",
            "Epoch 43/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.2212 - accuracy: 0.5804 - val_loss: 1.3742 - val_accuracy: 0.5122\n",
            "Epoch 44/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.2140 - accuracy: 0.5833 - val_loss: 1.3739 - val_accuracy: 0.5082\n",
            "Epoch 45/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.2088 - accuracy: 0.5862 - val_loss: 1.3896 - val_accuracy: 0.5081\n",
            "Epoch 46/50\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.2022 - accuracy: 0.5867 - val_loss: 1.3476 - val_accuracy: 0.5197\n",
            "Epoch 47/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.1971 - accuracy: 0.5885 - val_loss: 1.4209 - val_accuracy: 0.4981\n",
            "Epoch 48/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.1912 - accuracy: 0.5923 - val_loss: 1.3983 - val_accuracy: 0.5088\n",
            "Epoch 49/50\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.1841 - accuracy: 0.5952 - val_loss: 1.3545 - val_accuracy: 0.5203\n",
            "Epoch 50/50\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.1791 - accuracy: 0.5952 - val_loss: 1.3761 - val_accuracy: 0.5132\n",
            "Epoch 1\n",
            "Training accuracy: 0.3098999857902527\n",
            "Validation accuracy: 0.35740000009536743\n",
            "Epoch 2\n",
            "Training accuracy: 0.3730199933052063\n",
            "Validation accuracy: 0.3840000033378601\n",
            "Epoch 3\n",
            "Training accuracy: 0.3975600004196167\n",
            "Validation accuracy: 0.3815999925136566\n",
            "Epoch 4\n",
            "Training accuracy: 0.4129599928855896\n",
            "Validation accuracy: 0.4146000146865845\n",
            "Epoch 5\n",
            "Training accuracy: 0.42660000920295715\n",
            "Validation accuracy: 0.4251999855041504\n",
            "Epoch 6\n",
            "Training accuracy: 0.4358600080013275\n",
            "Validation accuracy: 0.42669999599456787\n",
            "Epoch 7\n",
            "Training accuracy: 0.44547998905181885\n",
            "Validation accuracy: 0.4287000000476837\n",
            "Epoch 8\n",
            "Training accuracy: 0.45339998602867126\n",
            "Validation accuracy: 0.44440001249313354\n",
            "Epoch 9\n",
            "Training accuracy: 0.4612799882888794\n",
            "Validation accuracy: 0.4465000033378601\n",
            "Epoch 10\n",
            "Training accuracy: 0.46445998549461365\n",
            "Validation accuracy: 0.4577000141143799\n",
            "Epoch 11\n",
            "Training accuracy: 0.4700999855995178\n",
            "Validation accuracy: 0.46129998564720154\n",
            "Epoch 12\n",
            "Training accuracy: 0.47721999883651733\n",
            "Validation accuracy: 0.4611999988555908\n",
            "Epoch 13\n",
            "Training accuracy: 0.4833199977874756\n",
            "Validation accuracy: 0.45329999923706055\n",
            "Epoch 14\n",
            "Training accuracy: 0.4878599941730499\n",
            "Validation accuracy: 0.4666999876499176\n",
            "Epoch 15\n",
            "Training accuracy: 0.4918600022792816\n",
            "Validation accuracy: 0.47269999980926514\n",
            "Epoch 16\n",
            "Training accuracy: 0.49654000997543335\n",
            "Validation accuracy: 0.4794999957084656\n",
            "Epoch 17\n",
            "Training accuracy: 0.49865999817848206\n",
            "Validation accuracy: 0.47519999742507935\n",
            "Epoch 18\n",
            "Training accuracy: 0.5051800012588501\n",
            "Validation accuracy: 0.47699999809265137\n",
            "Epoch 19\n",
            "Training accuracy: 0.5105999708175659\n",
            "Validation accuracy: 0.4788999855518341\n",
            "Epoch 20\n",
            "Training accuracy: 0.5123800039291382\n",
            "Validation accuracy: 0.47920000553131104\n",
            "Epoch 21\n",
            "Training accuracy: 0.515720009803772\n",
            "Validation accuracy: 0.48899999260902405\n",
            "Epoch 22\n",
            "Training accuracy: 0.5202999711036682\n",
            "Validation accuracy: 0.48159998655319214\n",
            "Epoch 23\n",
            "Training accuracy: 0.523639976978302\n",
            "Validation accuracy: 0.4894999861717224\n",
            "Epoch 24\n",
            "Training accuracy: 0.5303599834442139\n",
            "Validation accuracy: 0.49900001287460327\n",
            "Epoch 25\n",
            "Training accuracy: 0.530460000038147\n",
            "Validation accuracy: 0.5006999969482422\n",
            "Epoch 26\n",
            "Training accuracy: 0.5328400135040283\n",
            "Validation accuracy: 0.49129998683929443\n",
            "Epoch 27\n",
            "Training accuracy: 0.5362200140953064\n",
            "Validation accuracy: 0.4957999885082245\n",
            "Epoch 28\n",
            "Training accuracy: 0.5400800108909607\n",
            "Validation accuracy: 0.4867999851703644\n",
            "Epoch 29\n",
            "Training accuracy: 0.5415999889373779\n",
            "Validation accuracy: 0.4869000017642975\n",
            "Epoch 30\n",
            "Training accuracy: 0.5458599925041199\n",
            "Validation accuracy: 0.4997999966144562\n",
            "Epoch 31\n",
            "Training accuracy: 0.5489199757575989\n",
            "Validation accuracy: 0.5033000111579895\n",
            "Epoch 32\n",
            "Training accuracy: 0.5513399839401245\n",
            "Validation accuracy: 0.5077999830245972\n",
            "Epoch 33\n",
            "Training accuracy: 0.5550600290298462\n",
            "Validation accuracy: 0.5027999877929688\n",
            "Epoch 34\n",
            "Training accuracy: 0.5564799904823303\n",
            "Validation accuracy: 0.5149000287055969\n",
            "Epoch 35\n",
            "Training accuracy: 0.5580000281333923\n",
            "Validation accuracy: 0.5102999806404114\n",
            "Epoch 36\n",
            "Training accuracy: 0.5609599947929382\n",
            "Validation accuracy: 0.5134000182151794\n",
            "Epoch 37\n",
            "Training accuracy: 0.5669000148773193\n",
            "Validation accuracy: 0.5218999981880188\n",
            "Epoch 38\n",
            "Training accuracy: 0.5678200125694275\n",
            "Validation accuracy: 0.5066999793052673\n",
            "Epoch 39\n",
            "Training accuracy: 0.5699999928474426\n",
            "Validation accuracy: 0.5134000182151794\n",
            "Epoch 40\n",
            "Training accuracy: 0.5741199851036072\n",
            "Validation accuracy: 0.5073000192642212\n",
            "Epoch 41\n",
            "Training accuracy: 0.5763000249862671\n",
            "Validation accuracy: 0.4925000071525574\n",
            "Epoch 42\n",
            "Training accuracy: 0.57805997133255\n",
            "Validation accuracy: 0.5109999775886536\n",
            "Epoch 43\n",
            "Training accuracy: 0.5803999900817871\n",
            "Validation accuracy: 0.5121999979019165\n",
            "Epoch 44\n",
            "Training accuracy: 0.5832800269126892\n",
            "Validation accuracy: 0.5081999897956848\n",
            "Epoch 45\n",
            "Training accuracy: 0.5862200260162354\n",
            "Validation accuracy: 0.5080999732017517\n",
            "Epoch 46\n",
            "Training accuracy: 0.586679995059967\n",
            "Validation accuracy: 0.5196999907493591\n",
            "Epoch 47\n",
            "Training accuracy: 0.5885199904441833\n",
            "Validation accuracy: 0.49810001254081726\n",
            "Epoch 48\n",
            "Training accuracy: 0.5922600030899048\n",
            "Validation accuracy: 0.5088000297546387\n",
            "Epoch 49\n",
            "Training accuracy: 0.5951600074768066\n",
            "Validation accuracy: 0.5202999711036682\n",
            "Epoch 50\n",
            "Training accuracy: 0.5951600074768066\n",
            "Validation accuracy: 0.5131999850273132\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Write your code to build an MLP with one hidden layer of 1024 neurons,\n",
        "with an SGD optimizer. Train for 50 epochs, and output the training and\n",
        "validation accuracy at each epoch.\n",
        "\"\"\"\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoded vectors\n",
        "num_classes = 10\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Define MLP architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, activation='relu', input_shape=(32*32*3,)))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(), metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "batch_size = 128\n",
        "history = model.fit(x_train.reshape(-1, 32*32*3), y_train, validation_data=(x_test.reshape(-1, 32*32*3), y_test),\n",
        "                    epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Print training and validation accuracy at each epoch\n",
        "for epoch in range(epochs):\n",
        "    print(\"Epoch\", epoch+1)\n",
        "    print(\"Training accuracy:\", history.history['accuracy'][epoch])\n",
        "    print(\"Validation accuracy:\", history.history['val_accuracy'][epoch])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5qyTWmqbtp9"
      },
      "source": [
        "#### Question 2\n",
        "\n",
        "Complete the following table on the design choices for your MLP:\n",
        "\n",
        "| Hyperparameter       | What I used | Why?                  |\n",
        "|:---------------------|:------------|:----------------------|\n",
        "| Optimizer            | SGD         | few hyperpara to fine-tune |\n",
        "| # of hidden layers   | 1           |  |\n",
        "| # of hidden neurons  | 1024        |  |\n",
        "| Hid layer activation |  relu       |     time-efficient                  |\n",
        "| # of output neurons  |    10       |       10 classes to classify               |\n",
        "| Output activation    |softmax      |          make the sum of output is 1,each output neuron represent a possibility             |\n",
        "| lr                   |     0.01     |         the default para of SGD              |\n",
        "| momentum             |     0.9       |        the default para of SGD               |\n",
        "| decay                |      0.01       |    the default para of SGD                   |\n",
        "| loss                 | cross-entropy          |        For classification mission               |\n",
        "\n",
        "\n",
        "#### Question 3:\n",
        "\n",
        "What was your final training accuracy? Validation accuracy? Is there overfitting / underfitting? Explain your answer:\n",
        "\n",
        "**The final training accuracy is 0.596, the final validation accuracy is 0.51. There is underfitting since the training accuracy is low.**\n",
        "\n",
        "\n",
        "### 3.3 Experimenting with the MLP\n",
        "\n",
        "Cut and paste your code from Section 3.2 to the box below (you may need to rename your MLP). Experiment with the number of hidden layers, the number of neurons in each hidden layer, the optimization algorithm, etc. See [Keras Optimizers](https://keras.io/optimizers) for the types of optimizers and their parameters. **Train for 100 epochs.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvjRRUIkbtp-",
        "outputId": "d4a38f0b-b663-4028-f0d1-17a8c4fa30cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "391/391 [==============================] - 4s 6ms/step - loss: 1.9153 - accuracy: 0.3105 - val_loss: 1.7411 - val_accuracy: 0.3712\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.6814 - accuracy: 0.3952 - val_loss: 1.6255 - val_accuracy: 0.4235\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.5884 - accuracy: 0.4325 - val_loss: 1.5811 - val_accuracy: 0.4279\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.5343 - accuracy: 0.4533 - val_loss: 1.4978 - val_accuracy: 0.4674\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 1.4850 - accuracy: 0.4697 - val_loss: 1.4944 - val_accuracy: 0.4670\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.4420 - accuracy: 0.4861 - val_loss: 1.4835 - val_accuracy: 0.4741\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.4070 - accuracy: 0.4985 - val_loss: 1.4352 - val_accuracy: 0.4888\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.3764 - accuracy: 0.5085 - val_loss: 1.4166 - val_accuracy: 0.5005\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.3418 - accuracy: 0.5180 - val_loss: 1.4136 - val_accuracy: 0.4938\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.3130 - accuracy: 0.5302 - val_loss: 1.3743 - val_accuracy: 0.5134\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.2801 - accuracy: 0.5426 - val_loss: 1.4238 - val_accuracy: 0.4957\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.2506 - accuracy: 0.5531 - val_loss: 1.4403 - val_accuracy: 0.4890\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.2205 - accuracy: 0.5645 - val_loss: 1.3576 - val_accuracy: 0.5184\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.1845 - accuracy: 0.5753 - val_loss: 1.3698 - val_accuracy: 0.5205\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.1600 - accuracy: 0.5827 - val_loss: 1.4247 - val_accuracy: 0.5038\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.1427 - accuracy: 0.5896 - val_loss: 1.4018 - val_accuracy: 0.5143\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.1069 - accuracy: 0.6033 - val_loss: 1.4403 - val_accuracy: 0.4990\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.0756 - accuracy: 0.6149 - val_loss: 1.4622 - val_accuracy: 0.5084\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.0568 - accuracy: 0.6229 - val_loss: 1.4026 - val_accuracy: 0.5208\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 1.0178 - accuracy: 0.6323 - val_loss: 1.4362 - val_accuracy: 0.5195\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.9973 - accuracy: 0.6429 - val_loss: 1.4772 - val_accuracy: 0.5118\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.9665 - accuracy: 0.6538 - val_loss: 1.4902 - val_accuracy: 0.5144\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.9335 - accuracy: 0.6639 - val_loss: 1.4896 - val_accuracy: 0.5148\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.9105 - accuracy: 0.6750 - val_loss: 1.4773 - val_accuracy: 0.5207\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.8801 - accuracy: 0.6856 - val_loss: 1.4871 - val_accuracy: 0.5219\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.8432 - accuracy: 0.6972 - val_loss: 1.5448 - val_accuracy: 0.5183\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8191 - accuracy: 0.7056 - val_loss: 1.5967 - val_accuracy: 0.5134\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8000 - accuracy: 0.7141 - val_loss: 1.6047 - val_accuracy: 0.5159\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.7679 - accuracy: 0.7245 - val_loss: 1.6442 - val_accuracy: 0.5158\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.7368 - accuracy: 0.7350 - val_loss: 1.7015 - val_accuracy: 0.5083\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.7139 - accuracy: 0.7432 - val_loss: 1.7197 - val_accuracy: 0.5086\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.6848 - accuracy: 0.7554 - val_loss: 1.7719 - val_accuracy: 0.5071\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6774 - accuracy: 0.7567 - val_loss: 1.8117 - val_accuracy: 0.5086\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6399 - accuracy: 0.7712 - val_loss: 1.9054 - val_accuracy: 0.5074\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.6148 - accuracy: 0.7789 - val_loss: 1.9596 - val_accuracy: 0.5018\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.5892 - accuracy: 0.7889 - val_loss: 2.0360 - val_accuracy: 0.5052\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.5918 - accuracy: 0.7883 - val_loss: 2.0078 - val_accuracy: 0.5131\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.5764 - accuracy: 0.7921 - val_loss: 2.0574 - val_accuracy: 0.5114\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.5396 - accuracy: 0.8047 - val_loss: 2.1511 - val_accuracy: 0.5068\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.5405 - accuracy: 0.8041 - val_loss: 2.1050 - val_accuracy: 0.5021\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.5132 - accuracy: 0.8162 - val_loss: 2.2319 - val_accuracy: 0.4934\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.4968 - accuracy: 0.8193 - val_loss: 2.3546 - val_accuracy: 0.5002\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.4778 - accuracy: 0.8275 - val_loss: 2.3659 - val_accuracy: 0.5002\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.4508 - accuracy: 0.8397 - val_loss: 2.3579 - val_accuracy: 0.5018\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.4502 - accuracy: 0.8388 - val_loss: 2.4357 - val_accuracy: 0.5041\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.4495 - accuracy: 0.8361 - val_loss: 2.4898 - val_accuracy: 0.5064\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.4224 - accuracy: 0.8482 - val_loss: 2.6042 - val_accuracy: 0.4970\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.4031 - accuracy: 0.8538 - val_loss: 2.6956 - val_accuracy: 0.4986\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.4179 - accuracy: 0.8502 - val_loss: 2.6484 - val_accuracy: 0.4860\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3866 - accuracy: 0.8618 - val_loss: 2.7036 - val_accuracy: 0.4954\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3891 - accuracy: 0.8609 - val_loss: 2.7081 - val_accuracy: 0.4994\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.3740 - accuracy: 0.8654 - val_loss: 2.8402 - val_accuracy: 0.4973\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.3740 - accuracy: 0.8664 - val_loss: 2.8513 - val_accuracy: 0.5055\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.3491 - accuracy: 0.8730 - val_loss: 2.8689 - val_accuracy: 0.5049\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.3629 - accuracy: 0.8682 - val_loss: 2.9846 - val_accuracy: 0.5043\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.3496 - accuracy: 0.8755 - val_loss: 2.9744 - val_accuracy: 0.4940\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.3420 - accuracy: 0.8787 - val_loss: 3.1183 - val_accuracy: 0.4869\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3142 - accuracy: 0.8864 - val_loss: 3.1915 - val_accuracy: 0.4937\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.3103 - accuracy: 0.8879 - val_loss: 3.2202 - val_accuracy: 0.4903\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.3191 - accuracy: 0.8853 - val_loss: 3.2239 - val_accuracy: 0.4936\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3048 - accuracy: 0.8908 - val_loss: 3.3064 - val_accuracy: 0.4859\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3100 - accuracy: 0.8898 - val_loss: 3.2399 - val_accuracy: 0.4990\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.3071 - accuracy: 0.8902 - val_loss: 3.2966 - val_accuracy: 0.4921\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2781 - accuracy: 0.9006 - val_loss: 3.3940 - val_accuracy: 0.4990\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2772 - accuracy: 0.9025 - val_loss: 3.4647 - val_accuracy: 0.4812\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.3125 - accuracy: 0.8890 - val_loss: 3.6414 - val_accuracy: 0.4878\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2587 - accuracy: 0.9073 - val_loss: 3.6115 - val_accuracy: 0.4892\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.3079 - accuracy: 0.8895 - val_loss: 3.6144 - val_accuracy: 0.4888\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2717 - accuracy: 0.9043 - val_loss: 3.5041 - val_accuracy: 0.4982\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2619 - accuracy: 0.9046 - val_loss: 3.7324 - val_accuracy: 0.4976\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2515 - accuracy: 0.9108 - val_loss: 3.8009 - val_accuracy: 0.4871\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2846 - accuracy: 0.8985 - val_loss: 3.7743 - val_accuracy: 0.4945\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2713 - accuracy: 0.9038 - val_loss: 3.8193 - val_accuracy: 0.4952\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2429 - accuracy: 0.9133 - val_loss: 3.8723 - val_accuracy: 0.4953\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2665 - accuracy: 0.9058 - val_loss: 3.8527 - val_accuracy: 0.4908\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2512 - accuracy: 0.9111 - val_loss: 3.9340 - val_accuracy: 0.4941\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2300 - accuracy: 0.9179 - val_loss: 3.9976 - val_accuracy: 0.4960\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2503 - accuracy: 0.9107 - val_loss: 4.1407 - val_accuracy: 0.4921\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2396 - accuracy: 0.9147 - val_loss: 4.2109 - val_accuracy: 0.4855\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2199 - accuracy: 0.9216 - val_loss: 4.1504 - val_accuracy: 0.4921\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2439 - accuracy: 0.9142 - val_loss: 4.1969 - val_accuracy: 0.4881\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2299 - accuracy: 0.9185 - val_loss: 4.2776 - val_accuracy: 0.4927\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2063 - accuracy: 0.9269 - val_loss: 4.1033 - val_accuracy: 0.4909\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2241 - accuracy: 0.9208 - val_loss: 4.2029 - val_accuracy: 0.4911\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2369 - accuracy: 0.9181 - val_loss: 4.3908 - val_accuracy: 0.4921\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2187 - accuracy: 0.9241 - val_loss: 4.3846 - val_accuracy: 0.4930\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2048 - accuracy: 0.9279 - val_loss: 4.4704 - val_accuracy: 0.4934\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2546 - accuracy: 0.9118 - val_loss: 4.6237 - val_accuracy: 0.4793\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.2348 - accuracy: 0.9195 - val_loss: 4.4279 - val_accuracy: 0.4930\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.1835 - accuracy: 0.9352 - val_loss: 4.3866 - val_accuracy: 0.4901\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2064 - accuracy: 0.9269 - val_loss: 4.5523 - val_accuracy: 0.4899\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2085 - accuracy: 0.9271 - val_loss: 4.6731 - val_accuracy: 0.4860\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2338 - accuracy: 0.9196 - val_loss: 4.6876 - val_accuracy: 0.4927\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2028 - accuracy: 0.9302 - val_loss: 4.7806 - val_accuracy: 0.4881\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.1942 - accuracy: 0.9314 - val_loss: 4.7296 - val_accuracy: 0.4904\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2121 - accuracy: 0.9254 - val_loss: 4.6573 - val_accuracy: 0.4961\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2023 - accuracy: 0.9315 - val_loss: 4.8098 - val_accuracy: 0.4915\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 2s 5ms/step - loss: 0.2046 - accuracy: 0.9307 - val_loss: 4.8259 - val_accuracy: 0.4877\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.1653 - accuracy: 0.9425 - val_loss: 4.9839 - val_accuracy: 0.4944\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.2068 - accuracy: 0.9288 - val_loss: 4.9441 - val_accuracy: 0.4920\n",
            "Epoch 1\n",
            "Training accuracy: 0.310479998588562\n",
            "Validation accuracy: 0.37119999527931213\n",
            "Epoch 2\n",
            "Training accuracy: 0.39524000883102417\n",
            "Validation accuracy: 0.4235000014305115\n",
            "Epoch 3\n",
            "Training accuracy: 0.4325000047683716\n",
            "Validation accuracy: 0.4278999865055084\n",
            "Epoch 4\n",
            "Training accuracy: 0.45333999395370483\n",
            "Validation accuracy: 0.4674000144004822\n",
            "Epoch 5\n",
            "Training accuracy: 0.4696600139141083\n",
            "Validation accuracy: 0.46700000762939453\n",
            "Epoch 6\n",
            "Training accuracy: 0.48607999086380005\n",
            "Validation accuracy: 0.4740999937057495\n",
            "Epoch 7\n",
            "Training accuracy: 0.4984799921512604\n",
            "Validation accuracy: 0.4887999892234802\n",
            "Epoch 8\n",
            "Training accuracy: 0.5085399746894836\n",
            "Validation accuracy: 0.5005000233650208\n",
            "Epoch 9\n",
            "Training accuracy: 0.5180400013923645\n",
            "Validation accuracy: 0.49380001425743103\n",
            "Epoch 10\n",
            "Training accuracy: 0.5302199721336365\n",
            "Validation accuracy: 0.5134000182151794\n",
            "Epoch 11\n",
            "Training accuracy: 0.5425599813461304\n",
            "Validation accuracy: 0.49570000171661377\n",
            "Epoch 12\n",
            "Training accuracy: 0.5531399846076965\n",
            "Validation accuracy: 0.48899999260902405\n",
            "Epoch 13\n",
            "Training accuracy: 0.5644599795341492\n",
            "Validation accuracy: 0.5184000134468079\n",
            "Epoch 14\n",
            "Training accuracy: 0.5752800107002258\n",
            "Validation accuracy: 0.5205000042915344\n",
            "Epoch 15\n",
            "Training accuracy: 0.5826799869537354\n",
            "Validation accuracy: 0.5037999749183655\n",
            "Epoch 16\n",
            "Training accuracy: 0.5895599722862244\n",
            "Validation accuracy: 0.5142999887466431\n",
            "Epoch 17\n",
            "Training accuracy: 0.6033200025558472\n",
            "Validation accuracy: 0.49900001287460327\n",
            "Epoch 18\n",
            "Training accuracy: 0.6148800253868103\n",
            "Validation accuracy: 0.508400022983551\n",
            "Epoch 19\n",
            "Training accuracy: 0.6228799819946289\n",
            "Validation accuracy: 0.520799994468689\n",
            "Epoch 20\n",
            "Training accuracy: 0.632319986820221\n",
            "Validation accuracy: 0.5195000171661377\n",
            "Epoch 21\n",
            "Training accuracy: 0.6429399847984314\n",
            "Validation accuracy: 0.5117999911308289\n",
            "Epoch 22\n",
            "Training accuracy: 0.6538400053977966\n",
            "Validation accuracy: 0.5144000053405762\n",
            "Epoch 23\n",
            "Training accuracy: 0.6639000177383423\n",
            "Validation accuracy: 0.5148000121116638\n",
            "Epoch 24\n",
            "Training accuracy: 0.6749799847602844\n",
            "Validation accuracy: 0.5206999778747559\n",
            "Epoch 25\n",
            "Training accuracy: 0.6855599880218506\n",
            "Validation accuracy: 0.5218999981880188\n",
            "Epoch 26\n",
            "Training accuracy: 0.6972200274467468\n",
            "Validation accuracy: 0.5182999968528748\n",
            "Epoch 27\n",
            "Training accuracy: 0.7055799961090088\n",
            "Validation accuracy: 0.5134000182151794\n",
            "Epoch 28\n",
            "Training accuracy: 0.7140799760818481\n",
            "Validation accuracy: 0.5159000158309937\n",
            "Epoch 29\n",
            "Training accuracy: 0.7245200276374817\n",
            "Validation accuracy: 0.5157999992370605\n",
            "Epoch 30\n",
            "Training accuracy: 0.7349799871444702\n",
            "Validation accuracy: 0.5083000063896179\n",
            "Epoch 31\n",
            "Training accuracy: 0.743179976940155\n",
            "Validation accuracy: 0.5085999965667725\n",
            "Epoch 32\n",
            "Training accuracy: 0.7554399967193604\n",
            "Validation accuracy: 0.507099986076355\n",
            "Epoch 33\n",
            "Training accuracy: 0.7567200064659119\n",
            "Validation accuracy: 0.5085999965667725\n",
            "Epoch 34\n",
            "Training accuracy: 0.7712000012397766\n",
            "Validation accuracy: 0.5073999762535095\n",
            "Epoch 35\n",
            "Training accuracy: 0.7789199948310852\n",
            "Validation accuracy: 0.501800000667572\n",
            "Epoch 36\n",
            "Training accuracy: 0.7889400124549866\n",
            "Validation accuracy: 0.5052000284194946\n",
            "Epoch 37\n",
            "Training accuracy: 0.7882999777793884\n",
            "Validation accuracy: 0.5131000280380249\n",
            "Epoch 38\n",
            "Training accuracy: 0.7921199798583984\n",
            "Validation accuracy: 0.5113999843597412\n",
            "Epoch 39\n",
            "Training accuracy: 0.8047199845314026\n",
            "Validation accuracy: 0.5067999958992004\n",
            "Epoch 40\n",
            "Training accuracy: 0.8040800094604492\n",
            "Validation accuracy: 0.5020999908447266\n",
            "Epoch 41\n",
            "Training accuracy: 0.8162400126457214\n",
            "Validation accuracy: 0.4934000074863434\n",
            "Epoch 42\n",
            "Training accuracy: 0.8192999958992004\n",
            "Validation accuracy: 0.5001999735832214\n",
            "Epoch 43\n",
            "Training accuracy: 0.8275200128555298\n",
            "Validation accuracy: 0.5001999735832214\n",
            "Epoch 44\n",
            "Training accuracy: 0.8396999835968018\n",
            "Validation accuracy: 0.501800000667572\n",
            "Epoch 45\n",
            "Training accuracy: 0.8387799859046936\n",
            "Validation accuracy: 0.5041000247001648\n",
            "Epoch 46\n",
            "Training accuracy: 0.8360999822616577\n",
            "Validation accuracy: 0.5063999891281128\n",
            "Epoch 47\n",
            "Training accuracy: 0.8482400178909302\n",
            "Validation accuracy: 0.4970000088214874\n",
            "Epoch 48\n",
            "Training accuracy: 0.8537999987602234\n",
            "Validation accuracy: 0.4986000061035156\n",
            "Epoch 49\n",
            "Training accuracy: 0.8502399921417236\n",
            "Validation accuracy: 0.4860000014305115\n",
            "Epoch 50\n",
            "Training accuracy: 0.8618199825286865\n",
            "Validation accuracy: 0.49540001153945923\n",
            "Epoch 51\n",
            "Training accuracy: 0.8608800172805786\n",
            "Validation accuracy: 0.49939998984336853\n",
            "Epoch 52\n",
            "Training accuracy: 0.8653600215911865\n",
            "Validation accuracy: 0.49729999899864197\n",
            "Epoch 53\n",
            "Training accuracy: 0.8664199709892273\n",
            "Validation accuracy: 0.5055000185966492\n",
            "Epoch 54\n",
            "Training accuracy: 0.8729599714279175\n",
            "Validation accuracy: 0.5048999786376953\n",
            "Epoch 55\n",
            "Training accuracy: 0.8682399988174438\n",
            "Validation accuracy: 0.5042999982833862\n",
            "Epoch 56\n",
            "Training accuracy: 0.8755000233650208\n",
            "Validation accuracy: 0.49399998784065247\n",
            "Epoch 57\n",
            "Training accuracy: 0.8787400126457214\n",
            "Validation accuracy: 0.4869000017642975\n",
            "Epoch 58\n",
            "Training accuracy: 0.8864399790763855\n",
            "Validation accuracy: 0.4936999976634979\n",
            "Epoch 59\n",
            "Training accuracy: 0.8878999948501587\n",
            "Validation accuracy: 0.4902999997138977\n",
            "Epoch 60\n",
            "Training accuracy: 0.8853200078010559\n",
            "Validation accuracy: 0.4936000108718872\n",
            "Epoch 61\n",
            "Training accuracy: 0.8908200263977051\n",
            "Validation accuracy: 0.48590001463890076\n",
            "Epoch 62\n",
            "Training accuracy: 0.8898400068283081\n",
            "Validation accuracy: 0.49900001287460327\n",
            "Epoch 63\n",
            "Training accuracy: 0.8902000188827515\n",
            "Validation accuracy: 0.4921000003814697\n",
            "Epoch 64\n",
            "Training accuracy: 0.9005600214004517\n",
            "Validation accuracy: 0.49900001287460327\n",
            "Epoch 65\n",
            "Training accuracy: 0.9025200009346008\n",
            "Validation accuracy: 0.4812000095844269\n",
            "Epoch 66\n",
            "Training accuracy: 0.8889600038528442\n",
            "Validation accuracy: 0.4878000020980835\n",
            "Epoch 67\n",
            "Training accuracy: 0.9072800278663635\n",
            "Validation accuracy: 0.48919999599456787\n",
            "Epoch 68\n",
            "Training accuracy: 0.8895000219345093\n",
            "Validation accuracy: 0.4887999892234802\n",
            "Epoch 69\n",
            "Training accuracy: 0.9042800068855286\n",
            "Validation accuracy: 0.498199999332428\n",
            "Epoch 70\n",
            "Training accuracy: 0.9046400189399719\n",
            "Validation accuracy: 0.4975999891757965\n",
            "Epoch 71\n",
            "Training accuracy: 0.9107800126075745\n",
            "Validation accuracy: 0.4871000051498413\n",
            "Epoch 72\n",
            "Training accuracy: 0.8985000252723694\n",
            "Validation accuracy: 0.4945000112056732\n",
            "Epoch 73\n",
            "Training accuracy: 0.9037799835205078\n",
            "Validation accuracy: 0.4952000081539154\n",
            "Epoch 74\n",
            "Training accuracy: 0.9132999777793884\n",
            "Validation accuracy: 0.4952999949455261\n",
            "Epoch 75\n",
            "Training accuracy: 0.9058399796485901\n",
            "Validation accuracy: 0.49079999327659607\n",
            "Epoch 76\n",
            "Training accuracy: 0.9111400246620178\n",
            "Validation accuracy: 0.49410000443458557\n",
            "Epoch 77\n",
            "Training accuracy: 0.9179400205612183\n",
            "Validation accuracy: 0.4959999918937683\n",
            "Epoch 78\n",
            "Training accuracy: 0.9106600284576416\n",
            "Validation accuracy: 0.4921000003814697\n",
            "Epoch 79\n",
            "Training accuracy: 0.9147400259971619\n",
            "Validation accuracy: 0.4855000078678131\n",
            "Epoch 80\n",
            "Training accuracy: 0.9216399788856506\n",
            "Validation accuracy: 0.4921000003814697\n",
            "Epoch 81\n",
            "Training accuracy: 0.9142199754714966\n",
            "Validation accuracy: 0.48809999227523804\n",
            "Epoch 82\n",
            "Training accuracy: 0.9185000061988831\n",
            "Validation accuracy: 0.4927000105381012\n",
            "Epoch 83\n",
            "Training accuracy: 0.9269199967384338\n",
            "Validation accuracy: 0.4909000098705292\n",
            "Epoch 84\n",
            "Training accuracy: 0.9207800030708313\n",
            "Validation accuracy: 0.491100013256073\n",
            "Epoch 85\n",
            "Training accuracy: 0.9181200265884399\n",
            "Validation accuracy: 0.4921000003814697\n",
            "Epoch 86\n",
            "Training accuracy: 0.9240999817848206\n",
            "Validation accuracy: 0.49300000071525574\n",
            "Epoch 87\n",
            "Training accuracy: 0.9279199838638306\n",
            "Validation accuracy: 0.4934000074863434\n",
            "Epoch 88\n",
            "Training accuracy: 0.9117799997329712\n",
            "Validation accuracy: 0.47929999232292175\n",
            "Epoch 89\n",
            "Training accuracy: 0.9195399880409241\n",
            "Validation accuracy: 0.49300000071525574\n",
            "Epoch 90\n",
            "Training accuracy: 0.9351599812507629\n",
            "Validation accuracy: 0.4900999963283539\n",
            "Epoch 91\n",
            "Training accuracy: 0.9269400238990784\n",
            "Validation accuracy: 0.48989999294281006\n",
            "Epoch 92\n",
            "Training accuracy: 0.9271000027656555\n",
            "Validation accuracy: 0.4860000014305115\n",
            "Epoch 93\n",
            "Training accuracy: 0.9195799827575684\n",
            "Validation accuracy: 0.4927000105381012\n",
            "Epoch 94\n",
            "Training accuracy: 0.930180013179779\n",
            "Validation accuracy: 0.48809999227523804\n",
            "Epoch 95\n",
            "Training accuracy: 0.9313600063323975\n",
            "Validation accuracy: 0.4903999865055084\n",
            "Epoch 96\n",
            "Training accuracy: 0.9253600239753723\n",
            "Validation accuracy: 0.4961000084877014\n",
            "Epoch 97\n",
            "Training accuracy: 0.9315000176429749\n",
            "Validation accuracy: 0.49149999022483826\n",
            "Epoch 98\n",
            "Training accuracy: 0.9307399988174438\n",
            "Validation accuracy: 0.4876999855041504\n",
            "Epoch 99\n",
            "Training accuracy: 0.9424600005149841\n",
            "Validation accuracy: 0.4943999946117401\n",
            "Epoch 100\n",
            "Training accuracy: 0.9287999868392944\n",
            "Validation accuracy: 0.492000013589859\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Cut and paste your code from Section 3.2 below, then modify it to get\n",
        "much better results than what you had earlier. E.g. increase the number of\n",
        "nodes in the hidden layer, increase the number of hidden layers,\n",
        "change the optimizer, etc.\n",
        "\n",
        "Train for 100 epochs.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoded vectors\n",
        "num_classes = 10\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Define MLP architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, activation='relu', input_shape=(32*32*3,)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)  # Experiment with different optimizers and parameters\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 100  # Increase the number of epochs\n",
        "batch_size = 128\n",
        "history = model.fit(x_train.reshape(-1, 32*32*3), y_train, validation_data=(x_test.reshape(-1, 32*32*3), y_test),\n",
        "                    epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Print training and validation accuracy at each epoch\n",
        "for epoch in range(epochs):\n",
        "    print(\"Epoch\", epoch+1)\n",
        "    print(\"Training accuracy:\", history.history['accuracy'][epoch])\n",
        "    print(\"Validation accuracy:\", history.history['val_accuracy'][epoch])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3Plp5Jrbtp-"
      },
      "source": [
        "----\n",
        "\n",
        "#### Question 4:\n",
        "\n",
        "Complete the following table with your final design (you may add more rows for the # neurons (layer1) etc. to detail how many neurons you have in each hidden layer). Likewise you may replace the lr, momentum etc rows with parameters more appropriate to the optimizer that you have chosen.\n",
        "\n",
        "\n",
        "| Hyperparameter       | What I used | Why?                  |\n",
        "|:---------------------|:------------|:----------------------|\n",
        "| Optimizer            |       Adam      |      robust to hyperparameter choices                  |\n",
        "| # of hidden layers   |     3        |                       |\n",
        "| # neurons(layer1)    |        1024     |                       |\n",
        "| Hid layer1 activation|     relu        |  time-efficient                     |\n",
        "| # neurons(layer2)    |         512    |                       |\n",
        "| Hid layer2 activation|   relu          |   time-efficient                    |\n",
        "| # neurons(layer3)    |         256    |                       |\n",
        "| Hid layer3 activation|   relu          |  time-efficient                     |\n",
        "| # of output neurons  |         10    |           10 classes for classification            |\n",
        "| Output activation    |         softmax    |   make the sum of output is 1,each output neuron represent a possibility                    |\n",
        "| lr                   |      0.001       |       default para of Adam                |\n",
        "| beta_1             |         0.9    |    default para of Adam                    |\n",
        "| beta_2               |         0.999    |          default para of Adam             |\n",
        "| loss                 |       cross-entropy    |             For classification mission          |\n",
        "\n",
        "\n",
        "\n",
        "#### Question 5\n",
        "\n",
        "What is the final training and validation accuracy that you obtained after 150 epochs. Is there considerable improvement over Section 3.2? Are there still signs of underfitting or overfitting? Explain your answer.\n",
        "\n",
        "**The training accuracy is about 0.94 and the validation accuracy is about 0.49. There is considerable improvement since Section 3.2 only reach around 0.6 training accuracy. There is a sign of overfitting since from around 70 epoches, the validation accuracy is declining.**\n",
        "\n",
        "\n",
        "#### Question 6\n",
        "\n",
        "Write a short reflection on the practical difficulties of using a dense MLP to classsify images in the CIFAR-10 datasets.\n",
        "\n",
        "\n",
        "\n",
        "**Dimensionality**: The 32x32 color images have a total of 3,072 input features (32 x 32 x 3) when flattened to be fed into a dense MLP. This high dimensionality leads to a large number of parameters in the model, which can result in a slow training process and high computational requirements.\n",
        "\n",
        "**Loss of spatial information**: Dense MLPs treat input features independently and do not take into account the spatial relationships between pixels in an image. By flattening the image input, we lose important spatial and structural information that can be crucial for recognizing objects and patterns in images.\n",
        "\n",
        "**Overfitting**: Due to the high dimensionality and large number of parameters, dense MLPs are prone to overfitting, especially when the dataset is relatively small like CIFAR-10. Overfitting occurs when the model learns to memorize the training set instead of generalizing from the underlying patterns, resulting in poor performance on unseen data.\n",
        "\n",
        "**Limited translation invariance**: Dense MLPs do not have built-in translation invariance, meaning they cannot recognize the same object if it appears in different parts of the image. This limitation makes it difficult for MLPs to classify images in the CIFAR-10 dataset, where objects can appear in various positions and orientations.\n",
        "\n",
        "**Difficulty in handling varying scales**: Dense MLPs struggle to handle objects at varying scales within the image. Since the model does not have any mechanism to adapt its receptive field, it is not able to recognize objects at different scales effectively.\n",
        "\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "## 4. Creating a CNN for the MNIST Data Set\n",
        "\n",
        "In this section we will now create a convolutional neural network (CNN) to classify images in the MNIST dataset that we used in the previous lab. Let's go through each part to see how to do this.\n",
        "\n",
        "### 4.1 Loading the MNIST Dataset\n",
        "\n",
        "As always we will load the MNIST dataset, scale the inputs to between 0 and 1, and convert the Y labels to one-hot vectors. However unlike before we will not flatten the 28x28 image to a 784 element vector, since CNNs can inherently handle 2D data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rfL2kcrabtp-"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def load_mnist():\n",
        "    (train_x, train_y),(test_x, test_y) = mnist.load_data()\n",
        "    train_x = train_x.reshape(train_x.shape[0], 28, 28, 1)\n",
        "    test_x = test_x.reshape(test_x.shape[0], 28, 28, 1)\n",
        "\n",
        "    train_x=train_x.astype('float32')\n",
        "    test_x = test_x.astype('float32')\n",
        "\n",
        "    train_x /= 255.0\n",
        "    test_x /= 255.0\n",
        "\n",
        "    train_y = to_categorical(train_y, 10)\n",
        "    test_y = to_categorical(test_y, 10)\n",
        "\n",
        "    return (train_x, train_y), (test_x, test_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bde752o5btqA"
      },
      "source": [
        "### 4.2 Building the CNN\n",
        "\n",
        "We will now build the CNN. Unlike before we will create a function to produce the CNN. We will also look at how to save and load Keras models using \"checkpoints\", particularly \"ModelCheckpoint\" that saves the model each epoch.\n",
        "\n",
        "Let's begin by creating the model. We call os.path.exists to see if a model file exists, and call \"load_model\" if it does. Otherwise we create a new model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EWEZU7IPbtqA"
      },
      "outputs": [],
      "source": [
        "# load_model loads a model from a hd5 file.\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "MODEL_NAME = 'mnist-cnn.hd5'\n",
        "\n",
        "def buildmodel(model_name):\n",
        "    if os.path.exists(model_name):\n",
        "        model = load_model(model_name)\n",
        "    else:\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32, kernel_size=(5,5),\n",
        "        activation='relu',\n",
        "        input_shape=(28, 28, 1), padding='same')) # Question 7\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2,2), strides=2)) # Question 8\n",
        "        model.add(Conv2D(64, kernel_size=(5,5), activation='relu'))\n",
        "        model.add(Conv2D(128, kernel_size=(5,5), activation='relu'))\n",
        "        model.add(Conv2D(64, kernel_size=(5,5), activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "        model.add(Flatten()) # Question 9\n",
        "        model.add(Dense(1024, activation='relu'))\n",
        "        model.add(Dropout(0.1))\n",
        "        model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ9kDuQgbtqA"
      },
      "source": [
        "----\n",
        "\n",
        "#### Question 7\n",
        "\n",
        "The first layer in our CNN is a 2D convolution kernel, shown here:\n",
        "\n",
        "```\n",
        "        model.add(Conv2D(32, kernel_size=(5,5),\n",
        "        activation='relu',\n",
        "        input_shape=(28, 28, 1), padding='same')) # Question 7\n",
        "```\n",
        "\n",
        "Why is the input_shape set to (28, 28, 1)? What does this mean? What does \"padding = 'same'\" mean?\n",
        "\n",
        "**The input_shape is set to (28, 28, 1) to specify the dimensions of the input images that the CNN expects. It means that the CNN expects grayscale images with a resolution of 28 pixels by 28 pixels and a single color channel.**\n",
        "\n",
        "\n",
        "**The padding='same' parameter means that during the convolution operation, padding is applied to the input image in such a way that the output feature map has the same spatial dimensions as the input. Padding ensures that the information at the edges of the image is retained and helps avoid the loss of spatial information.**\n",
        "\n",
        "\n",
        "#### Question 8\n",
        "\n",
        "The second layer is the MaxPooling2D layer shown below:\n",
        "\n",
        "```\n",
        "        model.add(MaxPooling2D(pool_size=(2,2), strides=2)) # Question 8\n",
        "```\n",
        "\n",
        "What other types of pooling layers are available? What does 'strides = 2' mean?\n",
        "\n",
        "**Other types of pooling layers available in TensorFlow's Keras API include:**\n",
        "\n",
        "- AveragePooling2D: Computes the average value of each non-overlapping patch in the input feature map.\n",
        "\n",
        "- GlobalAveragePooling2D: Computes the average value across the entire spatial dimensions of the input feature map. It reduces each feature map to a single value.\n",
        "\n",
        "- GlobalMaxPooling2D: Computes the maximum value across the entire spatial dimensions of the input feature map. It reduces each feature map to a single value.\n",
        "\n",
        "**strides=2 means that the pooling operation moves by a stride of 2 pixels horizontally and vertically when pooling the input feature map. **\n",
        "\n",
        "\n",
        "#### Question 9\n",
        "\n",
        "What does the \"Flatten\" layer here do? Why is it needed?\n",
        "\n",
        "```\n",
        "        model.add(Flatten()) # Question 9\n",
        "```\n",
        "\n",
        "**The \"Flatten\" layer in a neural network reshapes the output from the previous layers into a 1-dimensional array.**\n",
        "\n",
        "**It is needed to prepare the data for fully connected layers that require a 1-dimensional input. The \"Flatten\" layer vectorizes the features, allowing the network to process and learn from the extracted features effectively. It transitions from spatial understanding to feature learning and maintains the correspondence between features from different spatial locations in the input data.**\n",
        "\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "### 4.3 Training the CNN\n",
        "\n",
        "Let's now train the CNN. In this example we introduce the idea of a \"callback\", which is a routine that Keras calls at the end of each epoch. Specifically we look at two callbacks:\n",
        "\n",
        "    1. ModelCheckpoint: When called, Keras saves the model to the specified filename.\n",
        "    \n",
        "    2. EarlyStopping: When called, Keras checks if it should stop the training prematurely.\n",
        "    \n",
        "\n",
        "Let's look at the code to see how training is done, and how callbacks are used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GUqyg7WHbtqB"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "def train(model, train_x, train_y, epochs, test_x, test_y, model_name):\n",
        "\n",
        "    model.compile(optimizer=SGD(lr=0.01, momentum=0.7),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    savemodel = ModelCheckpoint(model_name)\n",
        "    stopmodel = EarlyStopping(min_delta=0.001, patience=10) # Question 10\n",
        "\n",
        "    print(\"Starting training.\")\n",
        "\n",
        "    model.fit(x=train_x, y=train_y, batch_size=32,\n",
        "    validation_data=(test_x, test_y), shuffle=True,\n",
        "    epochs=epochs,\n",
        "    callbacks=[savemodel, stopmodel])\n",
        "\n",
        "    print(\"Done. Now evaluating.\")\n",
        "    loss, acc = model.evaluate(x=test_x, y=test_y)\n",
        "    print(\"Test accuracy: %3.2f, loss: %3.2f\"%(acc, loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuExlJ49btqB"
      },
      "source": [
        "Notice that there isn't very much that is unusual going on; we compile the model with our loss function and optimizer, then call fit, and finally evaluate to look at the final accuracy for the test set.  The only thing unusual is the \"callbacks\" parameter here in the fit function call\n",
        "\n",
        "```\n",
        "    model.fit(x=train_x, y=train_y, batch_size=32,\n",
        "    validation_data=(test_x, test_y), shuffle=True,\n",
        "    epochs=epochs,\n",
        "    callbacks=[savemodel, stopmodel])\n",
        "```\n",
        "\n",
        "----\n",
        "\n",
        "#### Question 10.\n",
        "\n",
        "What does do the min_delta and patience parameters do in the EarlyStopping callback, as shown below? (2 MARKS)\n",
        "\n",
        "```\n",
        "    stopmodel = EarlyStopping(min_delta=0.001, patience=10) # Question 10\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**min_delta**: This parameter represents the minimum change in the monitored metric that qualifies as an improvement. If the absolute change in the metric between the current epoch and the best recorded value is less than min_delta, the current epoch is considered as a non-improvement. The default value is 0, meaning that any improvement, no matter how small, will reset the patience counter.\n",
        "\n",
        "**patience**: This parameter is an integer that determines the number of consecutive non-improvement epochs allowed before stopping the training process. In other words, if the monitored metric does not improve for the specified number of consecutive epochs (as defined by min_delta), the training will be stopped early. The default value is 0, meaning the training will be stopped as soon as the metric stops improving.\n",
        "\n",
        "\n",
        "### 4.4 Putting it together.\n",
        "\n",
        "Now let's run the code and see how it goes (Note: To save time we are training for only 5 epochs; we should train much longer to get much better results):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TWFVjQ1vbtqB",
        "outputId": "6939e8c4-6903-43c5-b7bf-f26a6bd586cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training.\n",
            "Epoch 1/5\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.3672 - accuracy: 0.8809"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1875/1875 [==============================] - 18s 6ms/step - loss: 0.3672 - accuracy: 0.8809 - val_loss: 0.0767 - val_accuracy: 0.9754\n",
            "Epoch 2/5\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.0715 - accuracy: 0.9776"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1875/1875 [==============================] - 10s 5ms/step - loss: 0.0715 - accuracy: 0.9776 - val_loss: 0.0539 - val_accuracy: 0.9824\n",
            "Epoch 3/5\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9848"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1875/1875 [==============================] - 10s 5ms/step - loss: 0.0484 - accuracy: 0.9848 - val_loss: 0.0370 - val_accuracy: 0.9887\n",
            "Epoch 4/5\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.9880"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1875/1875 [==============================] - 10s 6ms/step - loss: 0.0369 - accuracy: 0.9881 - val_loss: 0.0401 - val_accuracy: 0.9862\n",
            "Epoch 5/5\n",
            "1865/1875 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9915"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.0316 - val_accuracy: 0.9900\n",
            "Done. Now evaluating.\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0316 - accuracy: 0.9900\n",
            "Test accuracy: 0.99, loss: 0.03\n"
          ]
        }
      ],
      "source": [
        "    (train_x, train_y),(test_x, test_y) = load_mnist()\n",
        "    model = buildmodel(MODEL_NAME)\n",
        "    train(model, train_x, train_y, 5, test_x, test_y, MODEL_NAME)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYBnYsQfbtqB"
      },
      "source": [
        "----\n",
        "\n",
        "#### Question 11.\n",
        "\n",
        "Compare the relative advantages and disadvantages of CNN vs. the Dense MLP that you build in sections 3.2 and 3.3. What makes CNNs better (or worse)?\n",
        "\n",
        "CNN (Convolutional Neural Network)\n",
        "\n",
        "---Advantages:\n",
        "\n",
        "**Preservation of spatial information**: CNNs use convolutional layers to scan and learn local patterns in the input images, preserving the spatial relationships between pixels. This ability to capture spatial information is crucial for image classification tasks, as it helps the model recognize patterns and objects in images more effectively.\n",
        "\n",
        "**Parameter efficiency**: CNNs use shared weights in their convolutional layers, which significantly reduces the number of parameters in the model compared to a dense MLP. This reduction in parameters leads to lower memory requirements and faster training times.\n",
        "\n",
        "**Translation invariance**: CNNs have built-in translation invariance due to their use of convolutional and pooling layers. This means that the model can recognize the same object or pattern, even if it appears in different parts of the image. This property is particularly important for image classification tasks, where objects can appear in various positions and orientations.\n",
        "\n",
        "**Handling varying scales**: CNNs can be designed with multiple layers and receptive fields of different sizes, enabling them to recognize objects and patterns at varying scales within the image.\n",
        "\n",
        "---Disadvantages:\n",
        "\n",
        "**Complexity**: CNNs are more complex than dense MLPs, both in terms of their architecture and the understanding required to effectively design and tune them.\n",
        "    \n",
        "**Computational resources**: CNNs can be computationally expensive, particularly for large models and high-resolution images. This can make training and inference slower and require more powerful hardware.\n",
        "\n",
        "Dense MLP (Multi-Layer Perceptron)\n",
        "\n",
        "---Advantages:\n",
        "\n",
        "**Simplicity**: Dense MLPs are simpler in their architecture compared to CNNs, making them easier to understand and implement. This can be an advantage for less complex tasks or for educational purposes.\n",
        "    \n",
        "**General-purpose**: Dense MLPs can be used for a wide range of tasks, including image classification. However, their performance on image classification tasks is generally worse than CNNs due to their inability to capture spatial information.\n",
        "\n",
        "---Disadvantages:\n",
        "\n",
        "**Loss of spatial information**: Dense MLPs do not explicitly consider the spatial relationships between pixels in an image, as they treat each input feature independently. This lack of spatial information can lead to poorer performance in image classification tasks.\n",
        "\n",
        "**Parameter inefficiency**: Dense MLPs have a larger number of parameters compared to CNNs, as each neuron in a layer is connected to every neuron in the previous layer. This can lead to increased memory requirements and longer training times.\n",
        "\n",
        "In summary, CNNs are generally better suited for image classification tasks because they can capture spatial information, have built-in translation invariance, and are more parameter-efficient than dense MLPs. However, CNNs are more complex and can require more computational resources. On the other hand, dense MLPs are simpler and more general-purpose but are less effective for image classification due to their inability to capture spatial information and their parameter inefficiency.\n",
        "\n",
        "## 5. Making a CNN for the CIFAR-10 Dataset\n",
        "\n",
        "Now comes the fun part: Using the example above for creating a CNN for the MNIST dataset, now create a CNN in the box below for the CIFAR-10 dataset. At the end of each epoch save the model to a file called \"cifar.hd5\" (note: the .hd5 is added automatically for you).\n",
        "\n",
        "---\n",
        "\n",
        "#### Question 12.\n",
        "\n",
        "Summarize your design in the table below (the actual coding cell comes after this):\n",
        "\n",
        "| Hyperparameter       | What I used | Why?                  |\n",
        "|:---------------------|:------------|:----------------------|\n",
        "| Optimizer            |      Adam       |              more effective , robust to hyperpara         |\n",
        "| Input shape          |      (32,32,3)       |             the RGB image shape          |\n",
        "| First layer          |     CNN channel num:32 kernel size(3,3)        |   extract feature                   |\n",
        "| Second layer         |     CNN channel num:32 kernel size(3,3)          |               extract feature               |     \n",
        "| 3nd layer          |     CNN channel num:64 kernel size(3,3)        |   combine these low-level features into more complex, higher-level features                    |\n",
        "| 4nd layer         |     CNN channel num:64 kernel size(3,3)          |               combine these low-level features into more complex, higher-level features        |\n",
        "| 5nd layer          |     CNN channel num:128 kernel size(3,3)        |   combine these low-level features into more complex, higher-level features                   |\n",
        "| 6nd layer         |     CNN channel num:128 kernel size(3,3)          |              combine these low-level features into more complex, higher-level features        |\n",
        "| Dense layer          |      128       |                       |\n",
        "| Dense layer          |      10      |   10 classes to classify                    |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g-h9BCh0btqB",
        "outputId": "7d6417ad-0cb5-4192-a844-2351dd4c3401",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "622/625 [============================>.] - ETA: 0s - loss: 1.8297 - accuracy: 0.3817\n",
            "Epoch 1: val_loss improved from inf to 1.30976, saving model to cifar.h5\n",
            "625/625 [==============================] - 14s 15ms/step - loss: 1.8269 - accuracy: 0.3825 - val_loss: 1.3098 - val_accuracy: 0.5236\n",
            "Epoch 2/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 1.2385 - accuracy: 0.5558\n",
            "Epoch 2: val_loss improved from 1.30976 to 1.09879, saving model to cifar.h5\n",
            "625/625 [==============================] - 9s 14ms/step - loss: 1.2385 - accuracy: 0.5558 - val_loss: 1.0988 - val_accuracy: 0.6076\n",
            "Epoch 3/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 1.0562 - accuracy: 0.6270\n",
            "Epoch 3: val_loss improved from 1.09879 to 1.06799, saving model to cifar.h5\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 1.0562 - accuracy: 0.6270 - val_loss: 1.0680 - val_accuracy: 0.6335\n",
            "Epoch 4/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.9508 - accuracy: 0.6656\n",
            "Epoch 4: val_loss improved from 1.06799 to 0.97033, saving model to cifar.h5\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.9500 - accuracy: 0.6658 - val_loss: 0.9703 - val_accuracy: 0.6624\n",
            "Epoch 5/100\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.8716 - accuracy: 0.6961\n",
            "Epoch 5: val_loss improved from 0.97033 to 0.75287, saving model to cifar.h5\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.8719 - accuracy: 0.6959 - val_loss: 0.7529 - val_accuracy: 0.7342\n",
            "Epoch 6/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.8172 - accuracy: 0.7136\n",
            "Epoch 6: val_loss did not improve from 0.75287\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.8172 - accuracy: 0.7136 - val_loss: 0.8708 - val_accuracy: 0.7020\n",
            "Epoch 7/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.7692 - accuracy: 0.7306\n",
            "Epoch 7: val_loss improved from 0.75287 to 0.73661, saving model to cifar.h5\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.7692 - accuracy: 0.7306 - val_loss: 0.7366 - val_accuracy: 0.7449\n",
            "Epoch 8/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.7265 - accuracy: 0.7492\n",
            "Epoch 8: val_loss improved from 0.73661 to 0.73308, saving model to cifar.h5\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.7267 - accuracy: 0.7491 - val_loss: 0.7331 - val_accuracy: 0.7488\n",
            "Epoch 9/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.6956 - accuracy: 0.7586\n",
            "Epoch 9: val_loss improved from 0.73308 to 0.60953, saving model to cifar.h5\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.6953 - accuracy: 0.7586 - val_loss: 0.6095 - val_accuracy: 0.7876\n",
            "Epoch 10/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.6643 - accuracy: 0.7701\n",
            "Epoch 10: val_loss did not improve from 0.60953\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.6640 - accuracy: 0.7702 - val_loss: 0.6186 - val_accuracy: 0.7843\n",
            "Epoch 11/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.6354 - accuracy: 0.7807\n",
            "Epoch 11: val_loss did not improve from 0.60953\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.6349 - accuracy: 0.7811 - val_loss: 0.6533 - val_accuracy: 0.7750\n",
            "Epoch 12/100\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.6081 - accuracy: 0.7903\n",
            "Epoch 12: val_loss improved from 0.60953 to 0.60577, saving model to cifar.h5\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.6079 - accuracy: 0.7904 - val_loss: 0.6058 - val_accuracy: 0.7926\n",
            "Epoch 13/100\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5954 - accuracy: 0.7963\n",
            "Epoch 13: val_loss improved from 0.60577 to 0.57362, saving model to cifar.h5\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.5954 - accuracy: 0.7964 - val_loss: 0.5736 - val_accuracy: 0.8019\n",
            "Epoch 14/100\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5745 - accuracy: 0.8034\n",
            "Epoch 14: val_loss improved from 0.57362 to 0.52445, saving model to cifar.h5\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.5748 - accuracy: 0.8033 - val_loss: 0.5245 - val_accuracy: 0.8190\n",
            "Epoch 15/100\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.5573 - accuracy: 0.8086\n",
            "Epoch 15: val_loss did not improve from 0.52445\n",
            "625/625 [==============================] - 9s 14ms/step - loss: 0.5578 - accuracy: 0.8085 - val_loss: 0.5409 - val_accuracy: 0.8144\n",
            "Epoch 16/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.5367 - accuracy: 0.8139\n",
            "Epoch 16: val_loss did not improve from 0.52445\n",
            "625/625 [==============================] - 10s 15ms/step - loss: 0.5367 - accuracy: 0.8139 - val_loss: 0.5369 - val_accuracy: 0.8126\n",
            "Epoch 17/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.5331 - accuracy: 0.8190\n",
            "Epoch 17: val_loss improved from 0.52445 to 0.48721, saving model to cifar.h5\n",
            "625/625 [==============================] - 9s 15ms/step - loss: 0.5329 - accuracy: 0.8190 - val_loss: 0.4872 - val_accuracy: 0.8329\n",
            "Epoch 18/100\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.5075 - accuracy: 0.8251\n",
            "Epoch 18: val_loss did not improve from 0.48721\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.5072 - accuracy: 0.8251 - val_loss: 0.5434 - val_accuracy: 0.8177\n",
            "Epoch 19/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.5050 - accuracy: 0.8269\n",
            "Epoch 19: val_loss did not improve from 0.48721\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.5050 - accuracy: 0.8269 - val_loss: 0.5069 - val_accuracy: 0.8264\n",
            "Epoch 20/100\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.4888 - accuracy: 0.8302\n",
            "Epoch 20: val_loss did not improve from 0.48721\n",
            "625/625 [==============================] - 9s 14ms/step - loss: 0.4888 - accuracy: 0.8303 - val_loss: 0.5318 - val_accuracy: 0.8251\n",
            "Epoch 21/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.4833 - accuracy: 0.8322\n",
            "Epoch 21: val_loss did not improve from 0.48721\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.4832 - accuracy: 0.8323 - val_loss: 0.4972 - val_accuracy: 0.8306\n",
            "Epoch 22/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.4724 - accuracy: 0.8369\n",
            "Epoch 22: val_loss did not improve from 0.48721\n",
            "625/625 [==============================] - 9s 14ms/step - loss: 0.4724 - accuracy: 0.8369 - val_loss: 0.5917 - val_accuracy: 0.8073\n",
            "Epoch 23/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.4691 - accuracy: 0.8390\n",
            "Epoch 23: val_loss improved from 0.48721 to 0.47316, saving model to cifar.h5\n",
            "625/625 [==============================] - 9s 14ms/step - loss: 0.4691 - accuracy: 0.8390 - val_loss: 0.4732 - val_accuracy: 0.8373\n",
            "Epoch 24/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.4549 - accuracy: 0.8419\n",
            "Epoch 24: val_loss did not improve from 0.47316\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.4543 - accuracy: 0.8421 - val_loss: 0.5825 - val_accuracy: 0.8124\n",
            "Epoch 25/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.4421 - accuracy: 0.8494\n",
            "Epoch 25: val_loss did not improve from 0.47316\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.4421 - accuracy: 0.8495 - val_loss: 0.5112 - val_accuracy: 0.8326\n",
            "Epoch 26/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.4440 - accuracy: 0.8451\n",
            "Epoch 26: val_loss did not improve from 0.47316\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.4439 - accuracy: 0.8451 - val_loss: 0.4824 - val_accuracy: 0.8413\n",
            "Epoch 27/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.8515\n",
            "Epoch 27: val_loss improved from 0.47316 to 0.44983, saving model to cifar.h5\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.4326 - accuracy: 0.8515 - val_loss: 0.4498 - val_accuracy: 0.8474\n",
            "Epoch 28/100\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.4319 - accuracy: 0.8512\n",
            "Epoch 28: val_loss did not improve from 0.44983\n",
            "625/625 [==============================] - 8s 14ms/step - loss: 0.4321 - accuracy: 0.8511 - val_loss: 0.4848 - val_accuracy: 0.8397\n",
            "Epoch 29/100\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.4181 - accuracy: 0.8555\n",
            "Epoch 29: val_loss did not improve from 0.44983\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.4184 - accuracy: 0.8555 - val_loss: 0.5088 - val_accuracy: 0.8356\n",
            "Epoch 30/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.4114 - accuracy: 0.8581\n",
            "Epoch 30: val_loss did not improve from 0.44983\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.4114 - accuracy: 0.8581 - val_loss: 0.4556 - val_accuracy: 0.8509\n",
            "Epoch 31/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.4083 - accuracy: 0.8577\n",
            "Epoch 31: val_loss did not improve from 0.44983\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.4083 - accuracy: 0.8577 - val_loss: 0.4972 - val_accuracy: 0.8372\n",
            "Epoch 32/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.4080 - accuracy: 0.8591\n",
            "Epoch 32: val_loss did not improve from 0.44983\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.4081 - accuracy: 0.8589 - val_loss: 0.4945 - val_accuracy: 0.8375\n",
            "Epoch 33/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.3946 - accuracy: 0.8641\n",
            "Epoch 33: val_loss did not improve from 0.44983\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.3947 - accuracy: 0.8640 - val_loss: 0.4691 - val_accuracy: 0.8480\n",
            "Epoch 34/100\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.3900 - accuracy: 0.8635\n",
            "Epoch 34: val_loss did not improve from 0.44983\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.3901 - accuracy: 0.8636 - val_loss: 0.5414 - val_accuracy: 0.8266\n",
            "Epoch 35/100\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.3829 - accuracy: 0.8682\n",
            "Epoch 35: val_loss did not improve from 0.44983\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.3830 - accuracy: 0.8682 - val_loss: 0.4517 - val_accuracy: 0.8543\n",
            "Epoch 36/100\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.3782 - accuracy: 0.8692\n",
            "Epoch 36: val_loss improved from 0.44983 to 0.42985, saving model to cifar.h5\n",
            "625/625 [==============================] - 9s 14ms/step - loss: 0.3785 - accuracy: 0.8691 - val_loss: 0.4298 - val_accuracy: 0.8585\n",
            "Epoch 37/100\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.3725 - accuracy: 0.8697\n",
            "Epoch 37: val_loss did not improve from 0.42985\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.3728 - accuracy: 0.8697 - val_loss: 0.4538 - val_accuracy: 0.8536\n",
            "Epoch 38/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.3708 - accuracy: 0.8710\n",
            "Epoch 38: val_loss did not improve from 0.42985\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.3708 - accuracy: 0.8711 - val_loss: 0.4406 - val_accuracy: 0.8554\n",
            "Epoch 39/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.3706 - accuracy: 0.8713\n",
            "Epoch 39: val_loss did not improve from 0.42985\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.3710 - accuracy: 0.8713 - val_loss: 0.4331 - val_accuracy: 0.8591\n",
            "Epoch 40/100\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.3603 - accuracy: 0.8748\n",
            "Epoch 40: val_loss did not improve from 0.42985\n",
            "625/625 [==============================] - 8s 14ms/step - loss: 0.3602 - accuracy: 0.8748 - val_loss: 0.4449 - val_accuracy: 0.8603\n",
            "Epoch 41/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3584 - accuracy: 0.8742\n",
            "Epoch 41: val_loss improved from 0.42985 to 0.42656, saving model to cifar.h5\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.3584 - accuracy: 0.8742 - val_loss: 0.4266 - val_accuracy: 0.8582\n",
            "Epoch 42/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.3512 - accuracy: 0.8775\n",
            "Epoch 42: val_loss did not improve from 0.42656\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.3516 - accuracy: 0.8774 - val_loss: 0.4583 - val_accuracy: 0.8510\n",
            "Epoch 43/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3582 - accuracy: 0.8746\n",
            "Epoch 43: val_loss improved from 0.42656 to 0.42396, saving model to cifar.h5\n",
            "625/625 [==============================] - 9s 14ms/step - loss: 0.3582 - accuracy: 0.8746 - val_loss: 0.4240 - val_accuracy: 0.8607\n",
            "Epoch 44/100\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.3451 - accuracy: 0.8797\n",
            "Epoch 44: val_loss did not improve from 0.42396\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.3447 - accuracy: 0.8799 - val_loss: 0.4449 - val_accuracy: 0.8565\n",
            "Epoch 45/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.3433 - accuracy: 0.8811\n",
            "Epoch 45: val_loss did not improve from 0.42396\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.3432 - accuracy: 0.8810 - val_loss: 0.4761 - val_accuracy: 0.8447\n",
            "Epoch 46/100\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.3378 - accuracy: 0.8824\n",
            "Epoch 46: val_loss did not improve from 0.42396\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.3377 - accuracy: 0.8825 - val_loss: 0.4342 - val_accuracy: 0.8598\n",
            "Epoch 47/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.3425 - accuracy: 0.8806\n",
            "Epoch 47: val_loss did not improve from 0.42396\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.3426 - accuracy: 0.8805 - val_loss: 0.4663 - val_accuracy: 0.8520\n",
            "Epoch 48/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.3352 - accuracy: 0.8835\n",
            "Epoch 48: val_loss did not improve from 0.42396\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.3354 - accuracy: 0.8834 - val_loss: 0.4423 - val_accuracy: 0.8584\n",
            "Epoch 49/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3327 - accuracy: 0.8837\n",
            "Epoch 49: val_loss did not improve from 0.42396\n",
            "625/625 [==============================] - 8s 14ms/step - loss: 0.3327 - accuracy: 0.8837 - val_loss: 0.4805 - val_accuracy: 0.8493\n",
            "Epoch 50/100\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.3280 - accuracy: 0.8862\n",
            "Epoch 50: val_loss did not improve from 0.42396\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.3283 - accuracy: 0.8861 - val_loss: 0.4508 - val_accuracy: 0.8573\n",
            "Epoch 51/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.3292 - accuracy: 0.8838\n",
            "Epoch 51: val_loss improved from 0.42396 to 0.41782, saving model to cifar.h5\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.3291 - accuracy: 0.8839 - val_loss: 0.4178 - val_accuracy: 0.8681\n",
            "Epoch 52/100\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.3236 - accuracy: 0.8884\n",
            "Epoch 52: val_loss did not improve from 0.41782\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.3235 - accuracy: 0.8884 - val_loss: 0.5281 - val_accuracy: 0.8335\n",
            "Epoch 53/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3249 - accuracy: 0.8877\n",
            "Epoch 53: val_loss did not improve from 0.41782\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.3249 - accuracy: 0.8877 - val_loss: 0.4610 - val_accuracy: 0.8527\n",
            "Epoch 54/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3185 - accuracy: 0.8889\n",
            "Epoch 54: val_loss did not improve from 0.41782\n",
            "625/625 [==============================] - 9s 14ms/step - loss: 0.3185 - accuracy: 0.8889 - val_loss: 0.4259 - val_accuracy: 0.8627\n",
            "Epoch 55/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.3151 - accuracy: 0.8907\n",
            "Epoch 55: val_loss did not improve from 0.41782\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.3156 - accuracy: 0.8905 - val_loss: 0.4451 - val_accuracy: 0.8595\n",
            "Epoch 56/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.3156 - accuracy: 0.8917\n",
            "Epoch 56: val_loss did not improve from 0.41782\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.3153 - accuracy: 0.8917 - val_loss: 0.4615 - val_accuracy: 0.8545\n",
            "Epoch 57/100\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.3111 - accuracy: 0.8913\n",
            "Epoch 57: val_loss did not improve from 0.41782\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.3111 - accuracy: 0.8913 - val_loss: 0.4268 - val_accuracy: 0.8644\n",
            "Epoch 58/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.8937\n",
            "Epoch 58: val_loss did not improve from 0.41782\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.3060 - accuracy: 0.8937 - val_loss: 0.4560 - val_accuracy: 0.8592\n",
            "Epoch 59/100\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.3069 - accuracy: 0.8941\n",
            "Epoch 59: val_loss did not improve from 0.41782\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.3072 - accuracy: 0.8941 - val_loss: 0.4268 - val_accuracy: 0.8628\n",
            "Epoch 60/100\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3026 - accuracy: 0.8958\n",
            "Epoch 60: val_loss did not improve from 0.41782\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.3026 - accuracy: 0.8958 - val_loss: 0.4186 - val_accuracy: 0.8693\n",
            "Epoch 61/100\n",
            "621/625 [============================>.] - ETA: 0s - loss: 0.3019 - accuracy: 0.8951Restoring model weights from the end of the best epoch: 51.\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.41782\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.3016 - accuracy: 0.8952 - val_loss: 0.4559 - val_accuracy: 0.8570\n",
            "Epoch 61: early stopping\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4306 - accuracy: 0.8640\n",
            "Test Loss: 0.4306, Test Accuracy: 86.40%\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(train_x, train_y), (test_x, test_y) = cifar10.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "train_x = train_x.astype('float32') / 255.0\n",
        "test_x = test_x.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "train_y = tf.keras.utils.to_categorical(train_y, num_classes=10)\n",
        "test_y = tf.keras.utils.to_categorical(test_y, num_classes=10)\n",
        "\n",
        "# Create a CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
        "\n",
        "# Define model checkpoint\n",
        "model_checkpoint = ModelCheckpoint('cifar.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_x, train_y, batch_size=64, epochs=100, validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_x, test_y, verbose=1)\n",
        "print(\"Test Loss: {:.4f}, Test Accuracy: {:.2f}%\".format(test_loss, test_accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEm9fC1ObtqC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}